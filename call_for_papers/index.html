<!DOCTYPE html><meta charset="utf-8"/><h1 id="call-for-papers">Call for Papers</h1>
<h2 id="overview">Overview</h2>
<p>The Workshop on Advancements in Sign Language Translation for Low-Resource Languages (SLT4LRL) invites submissions of archival and non-archival papers focused on modeling, understanding, and enhancing Sign Language Translation (SLT), with an emphasis on low-resource sign languages. This workshop seeks to bring together researchers and practitioners from the fields of NLP, computer vision, linguistics, accessibility, and Deaf studies to address the unique challenges posed by the visual-gestural nature and limited resources of many sign languages around the world.</p>
<p>Despite significant advances in speech and text-based translation, sign languages remain vastly underrepresented in research and technology. This workshop provides a platform to exchange ideas, showcase new research, and foster interdisciplinary collaborations to bridge the communication gap for Deaf and Hard of Hearing (DHH) communities worldwide.</p>
<br/>
<p><strong>Topics of interest include, but are not limited to</strong>:</p>
<p>Sign Language Translation (SLT) for Low-Resource Languages</p>
<p>Context-Aware or Multi-Modal Sign Language Translation</p>
<p>Cultural, Dialectal, and Regional Variations in Sign Languages</p>
<p>Contextual Reasoning and Disambiguation in SLT</p>
<p>Transfer Learning from High-Resource Sign Languages (e.g., ASL, DGS, CSL)</p>
<p>Sign Language Generation from Text or Speech</p>
<p>Bias Identification and Mitigation in SLT Models</p>
<p>Gloss-Free SLT Methods and End-to-End Architectures</p>
<p>Dataset Creation, Benchmarking, and Evaluation Protocols for SLT</p>
<p>Sign Language Recognition, Alignment, and Segmentation</p>
<p>Continuous Sign Language Translation (CSLT)</p>
<p>Applications of Large Vision-Language Models for SLT</p>
<p>Linguistic Representations and Modeling of Sign Languages</p>
<p>Pose Estimation, Gesture Tracking, and Facial Expression Analysis in SLT</p>
<p>Explainability, Interpretability, and Evaluation of SLT Systems</p>
<p>Human-in-the-Loop and Interactive SLT Systems</p>
<p>Ethical, Fairness, and Accessibility Considerations in SLT Research</p>
<p>We welcome contributions that span theoretical frameworks, empirical evaluations, novel datasets, practical applications, and interdisciplinary approaches that push the boundaries of sign language processing.</p>
<h2 id="paper-submission-information">Paper Submission Information</h2>
<p>We will accept submissions through <strong>OpenReview</strong> (submission link TBA).
All submissions should use the <a href="https://www.overleaf.com/latex/templates/association-for-computational-linguistics-acl-conference/jvxskxpnznfj">*ACL template</a> and <a href="https://acl-org.github.io/ACLPUB/formatting.html">formatting requirements</a>, following the official IJCNLP - AACL style guidelines. Archival paper must be fully anonymized.</p>
<h2 id="submission-types">Submission Types</h2>
<ul>
<li><strong>Archival papers</strong> of up to 8 pages + references. These are papers reporting on completed, original, and unpublished research. Papers shorter than this maximum are also welcome. An optional appendix may appear after the references in the same pdf file. Accepted papers are expected to be presented at the workshop and will be published in the workshop proceedings of the ACL Anthology, meaning they cannot be published elsewhere. They should report on obtained results rather than intended work. These papers will undergo double-blind peer-review, and should thus be anonymized.</li>
<li><strong>Non-archival extended abstracts</strong> of 2 pages + references. These may report on work in progress or may be cross-submissions that have already appeared (or are scheduled to appear) in another venue. These submissions are non-archival and will not be included in the proceedings. The selection will not be based on a double-blind review and thus submissions of this type need not be anonymized.</li>
</ul>
<br/>
<p>Accepted submissions for both tracks will be presented at the workshop: most as posters, some as oral presentations (determined by the program committee).</p>
<h2 id="important-dates">Important dates</h2>
<ul>
<li><strong>August 15th, 2025</strong> - Direct paper submission deadline (OpenReview, link TBD).</li>
<li><strong>September 5th, 2025</strong> - Commitment deadline for ARR papers (OpenReview, link TBD).</li>
<li><strong>September 15th, 2025</strong> - Notification of acceptance.</li>
<li><strong>October 3rd, 2025</strong> - Camera ready deadline.</li>
<li><strong>December 20th, 2025</strong> - Workshop date.</li>
</ul>
<h2 id="dual-submissions-and-preprints">Dual Submissions and Preprints</h2>
<p>Dual submissions <strong>are</strong> allowed for the archival track, but please check the dual submissions policy for the other venue that you are dual-submitting to. Papers posted to preprint servers such as arXiv can be submitted without any restrictions on when they were posted.</p>
<h2 id="camera-ready-information">Camera-ready information</h2>
<p>Authors of accepted archival papers should upload the final version of their paper to the submission system by the camera-ready deadline. Authors may use <strong>one extra page</strong> to address reviewer comments, for a total of nine pages + references. Broader Impacts/Ethics and Limitations sections are optional and can be included on a 10th page.</p>
<h2 id="contact">Contact</h2>
<p>Please contact the organizers at <a href="mailto:isign.benchmark@gmail.com"><a href="mailto:isign.benchmark@gmail.com">isign.benchmark@gmail.com</a></a> for any questions.</p>
<h2 id="anti-harassment-policy">Anti-Harassment Policy</h2>
<p>SLT4LRL 2025 adheres to the <a href="https://www.aclweb.org/adminwiki/index.php/Anti-Harassment_Policy">ACL Anti-Harassment Policy</a>.</p>